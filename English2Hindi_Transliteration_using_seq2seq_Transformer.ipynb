{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English2Hindi_Transliteration_using_seq2seq_Transformer.ipynb",
      "provenance": [],
      "mount_file_id": "1qHPfBNEoJR_0N1ye-_WSHCS3RIoiKuYS",
      "authorship_tag": "ABX9TyOCtNLV9nvaQj9/MxZur76B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarcasticvibes/English2Hindi-Transliteration-using-seq2seq-Transformers/blob/master/English2Hindi_Transliteration_using_seq2seq_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skWfn6WbfJQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "b803983e-7a80-4627-84b1-6362f8760989"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 4.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2531936f1b6adf2c6e5a6350577e7db07393d5a412a57e611f775599ea3f1305\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1fab32ff-699b-4826-a4f6-16a69d988bd3"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5a9216ce-65d7-47a3-ad1f-73c2ccc9d70f"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "5820ab7d-2c96-47de-834b-a136c719030e"
      },
      "source": [
        "test_data = TransliterationDataLoader('/content/drive/My Drive/TransliterationDataset/NEWS2012RefEnHi.xml')\n",
        "train_data = TransliterationDataLoader('/content/drive/My Drive/TransliterationDataset/NEWS2012TrainingEnHi.xml')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "29d58b76-b3db-4c61-dbe9-df2115aba306"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "SOMAPAAL - सोमपाल\n",
            "BIATHLON - बैथलन\n",
            "NAMUR - नामुर\n",
            "MUZZAMMIL - मुज़्ज़म्मिल\n",
            "NASSER - नासिर\n",
            "AIDEEN - ऐदीन\n",
            "TRANSPORT - ट्रांसपोर्ट\n",
            "PARK - पार्क\n",
            "FATIH - फतिह\n",
            "JASPER - जैस्पर\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "83a8dcb0-46fc-48c0-f205-3047b7b3a89d"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PATTHAR tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "bd7a1763-bddf-440b-e453-4d9b4bf0d7cc"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "पत्थर tensor([[43],\n",
            "        [37],\n",
            "        [78],\n",
            "        [38],\n",
            "        [49],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxSxy2ZgTCVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, has_mask=True):\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return F.log_softmax(output, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrhiYvS1GJgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positionalEncoding(nb_words, nb_dimensions, device):\n",
        "        X = torch.arange(0, nb_words).to(device, torch.float32)\n",
        "        Y = torch.arange(0, nb_dimensions).to(device, torch.float32)\n",
        "        Y, X = torch.meshgrid((Y, X))\n",
        "        Y, X = Y.t(), X.t()\n",
        "        TEMP = 10000\n",
        "        temp = torch.pow(TEMP, (2*Y)/nb_dimensions).to(torch.float32)\n",
        "        temp1 = torch.sin(X/temp)\n",
        "        temp2 = torch.cos(X/temp)\n",
        "        Z = torch.zeros((nb_words, nb_dimensions)).to(device)\n",
        "        Z[:,0::2] = temp1[:,0::2]\n",
        "        Z[:,1::2] = temp2[:,1::2]\n",
        "        return Z\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocabulary_size, d_model=32):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "        self.d_model = d_model\n",
        "        self.lookup_table = nn.Embedding(self.vocabulary_size, self.d_model, padding_idx=0)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        '''\n",
        "            Args:\n",
        "            X: tensor(nb_texts, nb_tokens)\n",
        "            Output:\n",
        "            tensor(nb_texts, nb_tokens, d_model(=size of one token))\n",
        "        '''\n",
        "        vectors = self.lookup_table(X)\n",
        "        return vectors + positionalEncoding(vectors.size(1), self.d_model, device_gpu)\n",
        "    \n",
        "    def get_weights(self):\n",
        "        return self.lookup_table.weight.data"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rQGFtG15Mau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransliterationModel(nn.Module):\n",
        "  def __init__(self, n_input, n_output, d_model, n_hidden, n_heads, dropout):\n",
        "    super(TransliterationModel, self).__init__()\n",
        "    self.embedding_encoder = Embedding(n_input, d_model=d_model)\n",
        "    self.embedding_decoder = Embedding(n_output, d_model=d_model)\n",
        "\n",
        "    self.transformer = nn.Transformer(d_model=d_model, \n",
        "                                      nhead=n_heads, \n",
        "                                      num_encoder_layers=n_hidden, \n",
        "                                      num_decoder_layers=n_hidden, \n",
        "                                      dropout=dropout)\n",
        "    \n",
        "    self.linear = nn.Linear(d_model, n_output, bias=False)\n",
        "\n",
        "\n",
        "  def forward(self, src, trgt):\n",
        "    src = self.embedding_encoder(src)\n",
        "    trgt = self.embedding_decoder(trgt)\n",
        "    output = self.transformer(src, trgt)\n",
        "\n",
        "    return self.linear(output)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlXA-PKoaD_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransliterationModel(27, 128, 64, 12, 16, .3)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr0uybtIKtf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b833f757-ba47-4e0e-e2cb-6296647c3b0d"
      },
      "source": [
        "model"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransliterationModel(\n",
              "  (embedding_encoder): Embedding(\n",
              "    (lookup_table): Embedding(27, 64, padding_idx=0)\n",
              "  )\n",
              "  (embedding_decoder): Embedding(\n",
              "    (lookup_table): Embedding(128, 64, padding_idx=0)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (3): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (4): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (5): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (6): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (7): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (8): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (9): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (10): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (11): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (3): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (4): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (5): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (6): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (7): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (8): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (9): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (10): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (11): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=64, out_features=128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csBPnbbLHy4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Embedding?"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcx93RCXJEVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}