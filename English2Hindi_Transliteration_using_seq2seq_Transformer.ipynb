{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English2Hindi_Transliteration_using_seq2seq_Transformer.ipynb",
      "provenance": [],
      "mount_file_id": "1qHPfBNEoJR_0N1ye-_WSHCS3RIoiKuYS",
      "authorship_tag": "ABX9TyO/ZHS7Pee6eN4sq8dlIiz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarcasticvibes/English2Hindi-Transliteration-using-seq2seq-Transformers/blob/master/English2Hindi_Transliteration_using_seq2seq_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skWfn6WbfJQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "b803983e-7a80-4627-84b1-6362f8760989"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 4.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 21.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 45.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2531936f1b6adf2c6e5a6350577e7db07393d5a412a57e611f775599ea3f1305\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNHewFZxOn2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "20ff3abf-36e7-4a51-cf03-c46b16907300"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "410e1f43-c7da-41db-d575-a1d32f933921"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dcfc0eec-8500-48db-e783-52f769ec0c0c"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "12fc234e-affd-459e-b221-c9970ec6f70e"
      },
      "source": [
        "test_data = TransliterationDataLoader('/content/drive/My Drive/TransliterationDataset/NEWS2012RefEnHi.xml')\n",
        "train_data = TransliterationDataLoader('/content/drive/My Drive/TransliterationDataset/NEWS2012TrainingEnHi.xml')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "ddad6b59-5d27-4b22-e259-9eb4ec2c9ad9"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "AJI - अजि\n",
            "SARANG - सारंग\n",
            "DESCARTES - डेसकार्टेस\n",
            "MRIGANAYANI - मृगनयनी\n",
            "ORMOND - ऑर्मंड\n",
            "SABZ - सब्ज़\n",
            "SAAZ - साज़\n",
            "ISLE - आइसल\n",
            "CHOR - चोर\n",
            "BANK - बैंक\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9ba63f8f-e95b-4fe3-e6b7-a3cc985aee58"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SIM tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "51b5a184-e6a6-4713-f00c-b2ade2ee102e"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "सिम tensor([[57],\n",
            "        [64],\n",
            "        [47],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxSxy2ZgTCVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, has_mask=True):\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return F.log_softmax(output, dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrhiYvS1GJgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def positionalEncoding(nb_words, nb_dimensions, device):\n",
        "        X = torch.arange(0, nb_words).to(device, torch.float32)\n",
        "        Y = torch.arange(0, nb_dimensions).to(device, torch.float32)\n",
        "        Y, X = torch.meshgrid((Y, X))\n",
        "        Y, X = Y.t(), X.t()\n",
        "        TEMP = 10000\n",
        "        temp = torch.pow(TEMP, (2*Y)/nb_dimensions).to(torch.float32)\n",
        "        temp1 = torch.sin(X/temp)\n",
        "        temp2 = torch.cos(X/temp)\n",
        "        Z = torch.zeros((nb_words, nb_dimensions)).to(device)\n",
        "        Z[:,0::2] = temp1[:,0::2]\n",
        "        Z[:,1::2] = temp2[:,1::2]\n",
        "        return Z\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocabulary_size, d_model=32):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "        self.d_model = d_model\n",
        "        self.lookup_table = nn.Embedding(self.vocabulary_size, self.d_model, padding_idx=0)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        '''\n",
        "            Args:\n",
        "            X: tensor(nb_texts, nb_tokens)\n",
        "            Output:\n",
        "            tensor(nb_texts, nb_tokens, d_model(=size of one token))\n",
        "        '''\n",
        "        vectors = self.lookup_table(X)\n",
        "        return vectors + positionalEncoding(vectors.size(1), self.d_model, device_gpu)\n",
        "    \n",
        "    def get_weights(self):\n",
        "        return self.lookup_table.weight.data"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rQGFtG15Mau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransliterationModel(nn.Module):\n",
        "  def __init__(self, n_input, n_output, d_model, n_hidden, n_heads, dropout):\n",
        "    super(TransliterationModel, self).__init__()\n",
        "    self.embedding_encoder = Embedding(n_input, d_model=d_model)\n",
        "    self.embedding_decoder = Embedding(n_output, d_model=d_model)\n",
        "\n",
        "    self.transformer = nn.Transformer(d_model=d_model, \n",
        "                                      nhead=n_heads, \n",
        "                                      num_encoder_layers=n_hidden, \n",
        "                                      num_decoder_layers=n_hidden, \n",
        "                                      dropout=dropout)\n",
        "    \n",
        "    self.linear = nn.Linear(d_model, n_output, bias=False)\n",
        "\n",
        "\n",
        "  def forward(self, src, trgt):\n",
        "    src = self.embedding_encoder(src)\n",
        "    trgt = self.embedding_decoder(trgt)\n",
        "    output = self.transformer(src, trgt)\n",
        "\n",
        "    return self.linear(output)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlXA-PKoaD_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = TransliterationModel(27, 128, 64, 12, 16, .3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr0uybtIKtf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b833f757-ba47-4e0e-e2cb-6296647c3b0d"
      },
      "source": [
        "model"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransliterationModel(\n",
              "  (embedding_encoder): Embedding(\n",
              "    (lookup_table): Embedding(27, 64, padding_idx=0)\n",
              "  )\n",
              "  (embedding_decoder): Embedding(\n",
              "    (lookup_table): Embedding(128, 64, padding_idx=0)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (3): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (4): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (5): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (6): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (7): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (8): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (9): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (10): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (11): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (3): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (4): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (5): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (6): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (7): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (8): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (9): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (10): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "        (11): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.3, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
              "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.3, inplace=False)\n",
              "          (dropout2): Dropout(p=0.3, inplace=False)\n",
              "          (dropout3): Dropout(p=0.3, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=64, out_features=128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcx93RCXJEVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu'):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = gt_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt)\n",
        "        #print(torch.argmax(outputs, dim=-1).shape, gt.shape)\n",
        "        loss = criterion(torch.argmax(outputs, dim=-1), gt)\n",
        "        loss.backward(retain_graph = True)\n",
        "        \n",
        "    opt.step()\n",
        "    return loss/batch_size"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veBeQ5BRNWHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device)/(i + 1))\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z_OXMhFNtWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "f5b59c8c-987a-47f7-e35a-c815749f654d"
      },
      "source": [
        "train_setup(model, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-c8fc63e8c04d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-a6ccdc145c3a>\u001b[0m in \u001b[0;36mtrain_setup\u001b[0;34m(net, lr, n_batches, batch_size, momentum, display_freq, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-47351a152874>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, opt, criterion, batch_size, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(torch.argmax(outputs, dim=-1).shape, gt.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    615\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2433\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: _th_exp_out not supported on CUDAType for Long"
          ]
        }
      ]
    }
  ]
}